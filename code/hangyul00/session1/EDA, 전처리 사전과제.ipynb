{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2bd32-1937-4200-bf34-866a1ac2d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분석 프로세스\n",
    "\n",
    "## 1. 데이터 수집\n",
    "\n",
    "## 2. 데이터 탐색(EDA)\n",
    "데이터 전처리를 수행하기 전후, 데이터 분석을 진행하면서 데이터를 여러 방식으로 파악하는 것\n",
    "\n",
    "## 3. 데이터 전처리\n",
    "결측치, 이상치를 적절히 처리하여 데이터의 왜곡을 피하는 것\n",
    "\n",
    "## 4. 데이터 모델링\n",
    "데이터에서 유용한 정보를 추출하기 위해 모델을 구축하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3a11c-4226-40a4-aec5-364c54eba84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "\n",
    "## EDA의 대상 (일변량/다변량)\n",
    "- **일변량**: 변수 1개 → 데이터 설명, 패턴 찾기\n",
    "- **다변량**: 여러 변수 간 관계 분석\n",
    "\n",
    "## EDA의 종류 (시각화/비시각화)\n",
    "- **시각화**: 차트, 그림을 활용해 데이터 탐색\n",
    "- **비시각화**: Summary Statistics 활용\n",
    "\n",
    "## EDA의 유형\n",
    "- **일변량 비시각화** → 데이터 분포 확인\n",
    "- **일변량 시각화** → 데이터 전체적 관찰\n",
    "- **다변량 비시각화** → 변수 간 관계 확인\n",
    "- **다변량 시각화** → 변수 간 관계 시각적 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9277c4-4eaa-43d0-a8b5-0a517bd09b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2254732150.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    ```python\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "## 1. 데이터 읽기\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"파일경로/파일이름.csv\")\n",
    "```\n",
    "\n",
    "## 2. 경로의 개념\n",
    "- **절대 경로**: `C:/Users/사용자/insight/파일이름.csv`\n",
    "- **상대 경로**:\n",
    "  - `./` 현재 디렉토리\n",
    "  - `../` 상위 디렉토리\n",
    "  - `/` 루트 디렉토리\n",
    "\n",
    "## 3. 데이터 파일 형식별 처리\n",
    "| 파일 형식 | 읽기         | 쓰기\n",
    "| CSV       | `read_csv`   | `to_csv`\n",
    "| JSON      | `read_json`  | `to_json`\n",
    "| HTML      | `read_html`  | `to_html`\n",
    "| Excel     | `read_excel` | `to_excel`\n",
    "| SQL       | `read_sql`   | `to_sql`\n",
    "\n",
    "# CSV 파일은 데이터를 쉼표로 구분하고 있는 텍스트 파일로 크기가 작고 압축이 용이함\n",
    "# excel 파일은 행과 열이 데이터프레임의 행, 열로 일대일 대응되는 파일로, 여러 시트로 구성된 데이터를 읽을 떄 시트 지정이 가능\n",
    "\n",
    "pd.read_excel('파일경로/파일이름.xlsx', sheet name=\"불러올 시트\")\n",
    "\n",
    "## 4. 데이터 미리보기\n",
    "```python\n",
    "df.head()  # 상위 5개 행 출력\n",
    "df.info()  # 데이터 요약 정보 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519b1cf-bddd-4a38-92c4-bf58d851ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 종류\n",
    "#범주형 데이터: 몇 개의 범주로 나누어진 데이터\n",
    "-\t명목형: 성별, 성공여부, 혈액형 등 순서 없이 분류만 된 데이터(A형, B형, O형)\n",
    "-\t순서형: 그들 사이에 순서 관계가 존재하는 데이터 (A->B->C)\n",
    "#수치형 데이터: 숫자로 표현되는 데이터\n",
    "-\t이산형: 정수 단위로 떨어지는 데이터 (자식의 수)\n",
    "-\t연속형: 연속적 값을 갖는 데이터(신장, 체중 등)\n",
    "** 정수면 이산형, 소수면 연속형이라고 할 수는 없음!\n",
    "예를 들어, 1학점짜리 과목, 1.5학점짜리 과목, 2학점짜리, 3학점짜리 과목이 있다면, 1학점에서 1.5학점이 이어지는게 아닌, 각각 하나씩 있는 과목이므로 연속된다고 볼 수 없음. 즉, 소수로 표현되었지만, 이산형 데이터임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda79249-bfd7-4892-97c9-1168525a1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "#전처리의 종류\n",
    "1)\t데이터 정제: 누락된 결측값을 보완하고, 이상치를 제거하는 것\n",
    "2)\t데이터 변환: 데이터 분석을 쉽게하기 위해 데이터를 변환해 일관성을 확보, 중복을 최소화해 데이터 분석 시간을 절약하는 것\n",
    "3)\t데이터 필터링: 오류를 발견하고, 삭제와 보정을 통해 품질을 향상시키는 것\n",
    "4)\t데이터 통합: 유사한 성질을 데이터를 통합하는 것\n",
    "\n",
    "# 결측값을 확인하는데 사용되는 함수\n",
    "1)\tInfo(): 데이터 프레임의 요약 정보를 출력하여 유효한 값의 개수를 알 수 있음\n",
    "2)\tValue_counts(dropna=False): na값을 drop하지 않으면서 결측값을 포함한 전체 데이터의 확인이 가능\n",
    "3)\tIsnull(): 누락 데이터면 true, 유효하면 false 반환함 (df.isnull().sum()의 형식으로 자주 사용됨)\n",
    "4)\tNotnull(): 유효 데이터면 true, 누락 데이터면 false 반환\n",
    "5)\tReplace(대체할 대상이 되는 값, 새롭게 바꿀 값)\n",
    "\n",
    "## 1. 결측값 확인 - 0이라는 값이 진짜 0인지, 아니면 결측되어 0으로 표기된 것인지 확인해야 함\n",
    "```python\n",
    "df.isnull().sum()  # 결측값 개수 확인\n",
    "df.notnull().sum() # 결측값이 아닌 개수 확인\n",
    "```\n",
    "\n",
    "## 2. 결측값 처리\n",
    "- **삭제**\n",
    "```python\n",
    "df.dropna(axis=0, how='any')  # 결측값 포함 행 삭제\n",
    "df.dropna(axis=1, how='all')  # 결측값 포함 열 삭제\n",
    "# how='any'인 경우는 하나라도 결측값이 있으면 삭제하고, 'all'인 경우에는 모든 값이 결측값이어야 삭제\n",
    "```\n",
    "df.dropna(axis=0, how='any'/'all', subset=[col1, col2..], inplace=True/False)\n",
    "subset을 통해 원하는 column을 기준으로 삭제할 수 있음\n",
    "inplace가 True이면 원본 dataframe 자체를 변경함. 디폴트 값을 inplace=False임\n",
    "\n",
    "- **대체**\n",
    "```python\n",
    "df.fillna(df['컬럼명'].mean(), inplace=True)  # 평균값으로 대체\n",
    "df.fillna(df['컬럼명'].median(), inplace=True) # 중앙값으로 대체\n",
    "```\n",
    "---\n",
    "대체할 때 유사 유형을 대체할 수도 있음\n",
    "df[‘value’] = df.groupby(‘Category’)[‘Value’].apply(lambda x: x.fillna(x.mean()))\n",
    "# df의 value 값을 채울건데, 각 category 별로 value값을 채우고, na값을 평균값으로 적용해서 대체할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ff237-6970-4771-bde1-956382cfd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 탐색\n",
    "\n",
    "## 1. 기술통계 확인\n",
    "```python\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "## 2. Boxplot을 통한 이상치 확인\n",
    "```python\n",
    "import matplotlib.pyplot as plt    -> df의 통계 정보를 반복해서 읽음\n",
    "df.boxplot(column=['컬럼명'])      -> 반복해서 읽은 df의 i 값으로 boxplot을 만듦\n",
    "plt.show()                         -> 표현함\n",
    "```\n",
    "\n",
    "## 3. Z-score를 통한 이상치 탐색\n",
    "데이터를 평균이 0, 표준편차가 1로 정규화하여 평균으로부터 얼마나 떨어졌는지를 확인함\n",
    "평균에 가까울수록 0에 가깝고, 멀수록 커짐\n",
    "보통 z-score가 2~3인 경우 이상치로 간주함\n",
    "```python\n",
    "from scipy import stats\n",
    "df['z_score'] = stats.zscore(df['컬럼명'])\n",
    "df[df['z_score'].abs() > 3]  # Z-score > 3 이상치 탐색\n",
    "```\n",
    "\n",
    "## 4. Tukey Fences 이상치 탐색\n",
    "사분위 범위(IQR)를 기반으로 두 가지 경우에 이상치라고 판단함\n",
    "Q1 – (1.5*IQR) 미만 / Q3+(1.5*IQR) 초과인 경우 이상치라고 판단함\n",
    "즉, 데이터의 상위 25%보다 위, 하위 25%보다 아래를 이상치라고 판단함\n",
    "\n",
    "\n",
    "이상치 제거하는 방법\n",
    "1.\t전체 삭제: 해당 관측치를 삭제 (human error인 경우)\n",
    "2.\t다른 값 대체: 관측치 자체가 적은 경우 삭제를 하면 신뢰성에 문제가 발생하므로 평균값이나 최빈값으로 대체하거나, 다른 변수를 사용해서 예측 모델을 만들고, 이상값을 예측하여 그 값으로 대체\n",
    "3.\t변수화: 이상값이 자연적으로 발생한 경우, 이상값에 대해 파악하는 것이 중요한데, 그 이상값이 나타난 이유를 확인하고, 자연스러운 값인 경우 해당 이상값을 제대로 분류하는 것이 필요함\n",
    "4.\t리샘플링: 이상값을 분리하여 모델을 만드는 것 -> 이상값을 대상에서 제외하는 것이 아닌, 이상값을 포함한 모델과 제외한 모델을 모두 만들고, 각각 모델에 대한 설명을 하는 것이 필요\n",
    "즉, 이상값이 자연발생한 값이라면 제외하지 않고, 케이스를 분리하는 것이 좋음\n",
    "\n",
    "# 예시 - Tukey fences로 이상치 찾기\n",
    "Def find_outlier_by_Tukey_DF(data, feature):\n",
    "\tq1, q3 = np.percentile(data[feature],[25,75])\n",
    "\tiqr = q3-q1\n",
    "\tlower_bound = q1 – (iqr * 1.5)\n",
    "\tupper_bound = q3 + (iqr * 1.5)\n",
    "\tprint(f'lower_bound는 {lower_bound.round(3)}, upper_bound는 {upper_bound.round(3)} 입니다')\n",
    "mask = data[(data[feature] > upper_bound) | (data[feature] < lower_bound)].index return mask. \n",
    "mask = find_outlier_by_Tukey_DF(df, 'BMI') \n",
    "print(f'해당 열의 이상치는 {len(mask)}개 입니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4f317-02f3-4844-896e-3fd8ceae674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 엔지니어링 - 전처리의 마지막 단계\n",
    "피처(변수)들의 형태를 변형하거나, 적절하게 처리하는 과정으로 \n",
    "새로운 데이터 또는 변수의 추가 없이 기존의 데이터를 보다 유용하게 만드는 방법\n",
    "\n",
    "## 1. 인코딩\n",
    "- **레이블 인코딩**\n",
    "레이블 인코딩의 경우 범주형 변수를 0부터 n-1까지의 숫자로 변환\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['컬럼명'] = le.fit_transform(df['컬럼명'])\n",
    "```\n",
    "- **원-핫 인코딩**\n",
    "원핫인코딩은 범주형 변수를 0과 1로 변환\n",
    "```python\n",
    "df = pd.get_dummies(df, columns=['컬럼명'])\n",
    "```\n",
    "## 2. 구간화\n",
    "일정한 구간으로 나눠서 분석하는 것 – 값들을 일정 범주로 나눈 다음에 해당 범주에서 데이터를 분석하는 것\n",
    "\n",
    "## 3. 변환\n",
    "기존의 피처를 다른 피처로 변환하여 변수를 추가하는 것\n",
    "예를 들어, 검수일자 피처를 변환하여 검수요일이라는 피처로 만들 수 있음\n",
    "\n",
    "## 4. 스케일링\n",
    "서로 다른 변수의 값 범위를 일정 수준으로 맞추는 작업\n",
    "숫자의 상대적인 크기 차이로 인해 결과가 왜곡되어 나타나는 현상을 막기 위해 “정규화” 작업을 수행하는 것\n",
    "표준화: 각 피처들의 평균을 0, 분산을 1로 변경하여 갖은 스케일을 갖게 만들게 됨\n",
    "MinMaxScaler: 모든 피처가 0과 1 사이에 위치하게 만드는 것인데, 데이터가 서로 다른 비율의 속성으로 구성되어 있을 때, \n",
    "같은 비율로 속성을 맞추는 것\n",
    "Sklearn 라이브러리는 StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler 등의 스케일러를 제공함\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['스케일링된 컬럼'] = scaler.fit_transform(df[['컬럼명']])\n",
    "```\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df['스케일링된 컬럼'] = scaler.fit_transform(df[['컬럼명']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b98bd0-f3da-4b1a-aa34-763379b7dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화\n",
    "숫자와 텍스트로 표현되는 정보를 그래프 등의 시각적 요소로 바꾸고, 이를 통해 데이터의 패턴, 관계, 추세를 파악하는 것\n",
    "Matplotlib나 Seaborn을 사용함\n",
    "시각화를 하기 전에 범주형인지, 수치형인지 파악 -> 결측값 및 이상치가 있는지 확인\n",
    "-> 데이터의 특성을 파악하고 어떤 그래프를 통해 데이터를 표현할 지를 고민해야 함\n",
    "\n",
    "파라미터\n",
    "매개변수(파라미터)는 프로그래밍된 함수의 입력값을 의미\n",
    "plt.figure(figsize=(5.4))\n",
    "sns.countplpot(data=data, x=’Survived’) 를 통해서 count를 갖는 막대그래프를 만들고, \n",
    "data=data, x=’Survived’에서 data와 x는 각각 countplot의 매개변수이고, data와 ‘Survived’는 실제 전달되는 인자\n",
    "즉, data와 x는 countplot에서의 입력값이 될 것이므로 매개변수가 되는 것임\n",
    "x축에 표현할 칼럼을 ‘Survived’로 지정한다는 의미\n",
    "\n",
    "Hue 파라미터\n",
    "Hue 파라미터에는 내가 원하는 변수를 기준으로 데이터를 구분하여 그래프에 표시할 수 있음\n",
    "plt.figure(figsize=(5.4))\n",
    "sns.countplot(data=data, x=’Survived’, hue=’Sex’) 를 통해서 \n",
    "성별이라는 변수를 통해서 데이터를 구분하여 그래프에 표시할 수 있음\n",
    "\n",
    "\n",
    "# 다양한 시각화 기법\n",
    "1.\tBoxplot (상자수염그림) – 사분위수와 이상치를 보여주는 그래프\n",
    "2.\tCountplot – 범주형 변수의 빈도수를 확인하는 그래프\n",
    "3.\tHisplot – 도수분포표 (수치형 변수의 구간별 빈도수를 보여줌)\n",
    "4.\tDisplot, kdeplot – 히스토그램을 연속적 곡선으로 연결한 그래프\n",
    "5.\tBarplot – 범주형 데이터 값 x에 따른 수치형 데이터 값 y의 평균을 제공\n",
    "barplot에서 나타나는 검은 선은 신뢰구간을 의미함. 막대의 평균 값이 얼마나 신뢰할 수 있는지를 나타내고, \n",
    "기본적으로 95%의 신뢰구간이 사용되는데, 선이 짧으면 데이터의 변동이 적고, 선이 길면 변동이 큼\n",
    "6.\tPointplot – 막대 그래프와 모양만 다르고 범주형 데이터 값 x에 따른 수치형 데이터 값 y의 평균을 제공함\n",
    "7.\tScatterplot – 산점도 그래프로 두 변수 간의 관계를 시각화하기 위해 사용됨\n",
    "8.\tRegplot – 회귀선이 추가된 산점도그래프\n",
    "9.\tCatplot – categoryplot의 줄임말로, 수치형 데이터와 범주형 데이터의 관계를 볼 때 사용함\n",
    "10.\tPieplot – 데이터의 부분과 전체 간의 비율을 표현하는 그래프이고, 비율을 강조하기 위해 사용하고, 모든 데이터가 합쳐서 전체를 이루는 경우에 효과적\n",
    "11.\tHeatmap – 변수간 상관계수를 볼 수 있는 그래프. Corr()을 통해서도 변수간 상관계수를 구하고, \n",
    "이를 히트맵에 표현할 수 있음\n",
    "상관계수는 두 수치형 변수 사이의 상관 관계의 정도를 수치적으로 나타낸 계수. 즉, 서로 영향을 주는 정도임.\n",
    "-1과 1 사이의 값을 가지며, -1과 1에 가까울수록 큰 상관계수를 가진다\n",
    "음의 상관계수: 하나가 커지면 다른 하나가 작아짐\n",
    "양의 상관계수: 하나가 커지면 다른 하나도 커짐\n",
    "12.\tViolinplot – 박스플롯과 커널밀도추정함수 그래프를 합친 그래프\n",
    "13.\t여러 그래프를 한번에 설정하는 그래프 – pairplot로 여러 변수간의 산점도를 한 번에 보여주는 그래프\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
